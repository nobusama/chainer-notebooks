{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPNPMxY5aVw9yyh2PEjJktZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nobusama/chainer-notebooks/blob/master/perturbation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4f3cvxWPXm6G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-tuning Pre-trained Model for Perturbation Prediction\n"
      ],
      "metadata": {
        "id": "qw0QjrWNXn8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJMjLb12Y67m",
        "outputId": "1efeba9d-d0f5-4e9c-bf11-3746e35d5f1a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cell-gears"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UrGuPNahKhM",
        "outputId": "b42e8c27-c9d6-4874-b60c-ba452f00d25c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cell-gears in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cell-gears) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from cell-gears) (2.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cell-gears) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from cell-gears) (1.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from cell-gears) (2.1.2)\n",
            "Requirement already satisfied: scanpy in /usr/local/lib/python3.10/dist-packages (from cell-gears) (1.10.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from cell-gears) (3.3)\n",
            "Requirement already satisfied: dcor in /usr/local/lib/python3.10/dist-packages (from cell-gears) (0.6)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.10/dist-packages (from dcor->cell-gears) (0.58.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dcor->cell-gears) (1.11.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from dcor->cell-gears) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->cell-gears) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cell-gears) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cell-gears) (2024.1)\n",
            "Requirement already satisfied: anndata>=0.8 in /usr/local/lib/python3.10/dist-packages (from scanpy->cell-gears) (0.10.8)\n",
            "Requirement already satisfied: h5py>=3.1 in /usr/local/lib/python3.10/dist-packages (from scanpy->cell-gears) (3.9.0)\n",
            "Requirement already satisfied: legacy-api-wrap>=1.4 in /usr/local/lib/python3.10/dist-packages (from scanpy->cell-gears) (1.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from scanpy->cell-gears) (3.7.1)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy->cell-gears) (8.4.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scanpy->cell-gears) (24.1)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy->cell-gears) (0.5.6)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from scanpy->cell-gears) (0.5.13)\n",
            "Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy->cell-gears) (0.13.1)\n",
            "Requirement already satisfied: session-info in /usr/local/lib/python3.10/dist-packages (from scanpy->cell-gears) (1.0.0)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy->cell-gears) (0.14.2)\n",
            "Requirement already satisfied: umap-learn!=0.5.0,>=0.5 in /usr/local/lib/python3.10/dist-packages (from scanpy->cell-gears) (0.5.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->cell-gears) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (1.13.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->cell-gears) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->cell-gears) (12.5.82)\n",
            "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->scanpy->cell-gears) (1.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->scanpy->cell-gears) (1.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy->cell-gears) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy->cell-gears) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy->cell-gears) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy->cell-gears) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy->cell-gears) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy->cell-gears) (3.1.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51->dcor->cell-gears) (0.41.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->cell-gears) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->cell-gears) (2.1.5)\n",
            "Requirement already satisfied: stdlib-list in /usr/local/lib/python3.10/dist-packages (from session-info->scanpy->cell-gears) (0.10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->cell-gears) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scgpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JhBbP0XiwQL",
        "outputId": "236f4dd5-a738-4b04-9288-d8233a40b3b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scgpt in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: cell-gears<0.0.3 in /usr/local/lib/python3.10/dist-packages (from scgpt) (0.0.2)\n",
            "Requirement already satisfied: datasets<3.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from scgpt) (2.20.0)\n",
            "Requirement already satisfied: leidenalg>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from scgpt) (0.10.2)\n",
            "Requirement already satisfied: numba>=0.55.1 in /usr/local/lib/python3.10/dist-packages (from scgpt) (0.58.1)\n",
            "Requirement already satisfied: orbax<0.1.8 in /usr/local/lib/python3.10/dist-packages (from scgpt) (0.1.7)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from scgpt) (2.0.3)\n",
            "Requirement already satisfied: scanpy<2.0.0,>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from scgpt) (1.10.2)\n",
            "Requirement already satisfied: scib<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from scgpt) (1.1.5)\n",
            "Requirement already satisfied: scikit-misc>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from scgpt) (0.4.0)\n",
            "Requirement already satisfied: scvi-tools<1.0,>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from scgpt) (0.20.3)\n",
            "Requirement already satisfied: torch<2.2,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from scgpt) (2.1.2)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (from scgpt) (0.16.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from scgpt) (4.12.2)\n",
            "Requirement already satisfied: umap-learn>=0.5.3 in /usr/local/lib/python3.10/dist-packages (from scgpt) (0.5.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cell-gears<0.0.3->scgpt) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cell-gears<0.0.3->scgpt) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from cell-gears<0.0.3->scgpt) (1.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from cell-gears<0.0.3->scgpt) (3.3)\n",
            "Requirement already satisfied: dcor in /usr/local/lib/python3.10/dist-packages (from cell-gears<0.0.3->scgpt) (0.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (6.0.1)\n",
            "Requirement already satisfied: igraph<0.12,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from leidenalg>=0.8.10->scgpt) (0.11.6)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.1->scgpt) (0.41.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from orbax<0.1.8->scgpt) (1.4.0)\n",
            "Requirement already satisfied: cached_property in /usr/local/lib/python3.10/dist-packages (from orbax<0.1.8->scgpt) (1.5.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from orbax<0.1.8->scgpt) (6.4.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from orbax<0.1.8->scgpt) (1.0.8)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.10/dist-packages (from orbax<0.1.8->scgpt) (1.7.0)\n",
            "Requirement already satisfied: jax>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from orbax<0.1.8->scgpt) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from orbax<0.1.8->scgpt) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: tensorstore>=0.1.20 in /usr/local/lib/python3.10/dist-packages (from orbax<0.1.8->scgpt) (0.1.45)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax<0.1.8->scgpt) (1.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->scgpt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->scgpt) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->scgpt) (2024.1)\n",
            "Requirement already satisfied: anndata>=0.8 in /usr/local/lib/python3.10/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.10.8)\n",
            "Requirement already satisfied: h5py>=3.1 in /usr/local/lib/python3.10/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (3.9.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (1.4.2)\n",
            "Requirement already satisfied: legacy-api-wrap>=1.4 in /usr/local/lib/python3.10/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (1.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (3.7.1)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (8.4.0)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.5.6)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.5.13)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (1.11.4)\n",
            "Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.13.1)\n",
            "Requirement already satisfied: session-info in /usr/local/lib/python3.10/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (1.0.0)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.14.2)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from scib<2.0.0,>=1.0.3->scgpt) (1.4.2)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from scib<2.0.0,>=1.0.3->scgpt) (1.2.14)\n",
            "Requirement already satisfied: chex in /usr/local/lib/python3.10/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.1.86)\n",
            "Requirement already satisfied: docrep>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.3.2)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.8.4)\n",
            "Requirement already satisfied: ml-collections>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.1.1)\n",
            "Requirement already satisfied: mudata>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.2.4)\n",
            "Requirement already satisfied: numpyro in /usr/local/lib/python3.10/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.15.1)\n",
            "Requirement already satisfied: openpyxl>=3.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (3.1.5)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.2.2)\n",
            "Requirement already satisfied: pyro-ppl>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (1.9.1)\n",
            "Requirement already satisfied: pytorch-lightning<1.10.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (1.9.5)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (13.7.1)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (1.4.0.post0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (1.13.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.13.0->scgpt) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.2,>=1.13.0->scgpt) (12.5.82)\n",
            "Requirement already satisfied: torchdata==0.7.1 in /usr/local/lib/python3.10/dist-packages (from torchtext->scgpt) (0.7.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1->torchtext->scgpt) (2.0.7)\n",
            "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->scanpy<2.0.0,>=1.9.1->scgpt) (1.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->scanpy<2.0.0,>=1.9.1->scgpt) (1.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from docrep>=0.3.2->scvi-tools<1.0,>=0.16.0->scgpt) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (4.0.3)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from igraph<0.12,>=0.10.0->leidenalg>=0.8.10->scgpt) (1.7.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.6->orbax<0.1.8->scgpt) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.6->orbax<0.1.8->scgpt) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy<2.0.0,>=1.9.1->scgpt) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy<2.0.0,>=1.9.1->scgpt) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy<2.0.0,>=1.9.1->scgpt) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy<2.0.0,>=1.9.1->scgpt) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy<2.0.0,>=1.9.1->scgpt) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy<2.0.0,>=1.9.1->scgpt) (3.1.2)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections>=0.1.1->scvi-tools<1.0,>=0.16.0->scgpt) (21.6.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl>=3.0->scvi-tools<1.0,>=0.16.0->scgpt) (1.1.0)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.6.0->scvi-tools<1.0,>=0.16.0->scgpt) (0.1.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<1.10.0,>=1.9.0->scvi-tools<1.0,>=0.16.0->scgpt) (0.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scgpt) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scgpt) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scgpt) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->scvi-tools<1.0,>=0.16.0->scgpt) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->scvi-tools<1.0,>=0.16.0->scgpt) (2.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->cell-gears<0.0.3->scgpt) (3.5.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex->scvi-tools<1.0,>=0.16.0->scgpt) (0.12.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->scib<2.0.0,>=1.0.3->scgpt) (1.14.1)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->scvi-tools<1.0,>=0.16.0->scgpt) (0.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.2,>=1.13.0->scgpt) (2.1.5)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from numpyro->scvi-tools<1.0,>=0.16.0->scgpt) (1.0.0)\n",
            "Requirement already satisfied: stdlib-list in /usr/local/lib/python3.10/dist-packages (from session-info->scanpy<2.0.0,>=1.9.1->scgpt) (0.10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.2,>=1.13.0->scgpt) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.6.0.post0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools<1.0,>=0.16.0->scgpt) (67.7.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->scvi-tools<1.0,>=0.16.0->scgpt) (0.1.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scgpt) (3.20.3)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils->orbax<0.1.8->scgpt) (3.19.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExtBovgmnXUk",
        "outputId": "7ce6994d-f2b9-4207-872e-40c13edf5645"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/save/scGPT_human"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1cZiMuMn8gR",
        "outputId": "c258845b-a25c-47ba-d4fc-f24562c44967"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "args.json  best_model.pt  vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import copy\n",
        "from pathlib import Path\n",
        "from typing import Iterable, List, Tuple, Dict, Union, Optional\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchtext.vocab import Vocab\n",
        "from torchtext._torchtext import (\n",
        "    Vocab as VocabPybind,\n",
        ")\n",
        "from torch_geometric.loader import DataLoader\n",
        "from gears import PertData, GEARS\n",
        "from gears.inference import compute_metrics, deeper_analysis, non_dropout_analysis\n",
        "from gears.utils import create_cell_graph_dataset_for_prediction\n",
        "\n",
        "#sys.path.insert(0, \"../\")\n",
        "\n",
        "import scgpt as scg\n",
        "from scgpt.model import TransformerGenerator\n",
        "from scgpt.loss import (\n",
        "    masked_mse_loss,\n",
        "    criterion_neg_log_bernoulli,\n",
        "    masked_relative_error,\n",
        ")\n",
        "from scgpt.tokenizer import tokenize_batch, pad_batch, tokenize_and_pad_batch\n",
        "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
        "from scgpt.utils import set_seed, map_raw_id_to_vocab_id\n",
        "\n",
        "matplotlib.rcParams[\"savefig.transparent\"] = False\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "set_seed(42)\n"
      ],
      "metadata": {
        "id": "kTcxoVYFXs0p"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Settings"
      ],
      "metadata": {
        "id": "4r9fIhk4jvZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# settings for data prcocessing\n",
        "pad_token = \"<pad>\"\n",
        "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
        "pad_value = 0  # for padding values\n",
        "pert_pad_id = 2\n",
        "\n",
        "n_hvg = 0  # number of highly variable genes\n",
        "include_zero_gene = \"all\"  # include zero expr genes in training input, \"all\", \"batch-wise\", \"row-wise\", or False\n",
        "max_seq_len = 1536\n",
        "\n",
        "# settings for training\n",
        "MLM = True  # whether to use masked language modeling, currently it is always on.\n",
        "CLS = False  # celltype classification objective\n",
        "CCE = False  # Contrastive cell embedding objective\n",
        "MVC = False  # Masked value prediction for cell embedding\n",
        "ECS = False  # Elastic cell similarity objective\n",
        "cell_emb_style = \"cls\"\n",
        "mvc_decoder_style = \"inner product, detach\"\n",
        "amp = True\n",
        "load_model = \"/content/drive/MyDrive/save/scGPT_human\"\n",
        "load_param_prefixs = [\n",
        "    \"encoder\",\n",
        "    \"value_encoder\",\n",
        "    \"transformer_encoder\",\n",
        "]\n",
        "\n",
        "# settings for optimizer\n",
        "lr = 1e-4  # or 1e-4\n",
        "batch_size = 32\n",
        "eval_batch_size = 32\n",
        "epochs = 15\n",
        "schedule_interval = 1\n",
        "early_stop = 5\n",
        "\n",
        "# settings for the model\n",
        "embsize = 512  # embedding dimension\n",
        "d_hid = 512  # dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 12  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 8  # number of heads in nn.MultiheadAttention\n",
        "n_layers_cls = 3\n",
        "dropout = 0.2  # dropout probability\n",
        "use_fast_transformer = True  # whether to use fast transformer\n",
        "\n",
        "# logging\n",
        "log_interval = 100\n",
        "\n",
        "# dataset and evaluation choices\n",
        "data_name = \"adamson\"\n",
        "split = \"simulation\"\n",
        "if data_name == \"norman\":\n",
        "    perts_to_plot = [\"SAMD1+ZBTB1\"]\n",
        "elif data_name == \"adamson\":\n",
        "    perts_to_plot = [\"KCTD16+ctrl\"]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "kxlEqZkxYQfy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = Path(f\"./save/dev_perturb_{data_name}-{time.strftime('%b%d-%H-%M')}/\")\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"saving to {save_dir}\")\n",
        "\n",
        "logger = scg.logger\n",
        "scg.utils.add_file_handler(logger, save_dir / \"run.log\")\n",
        "# log running date and current git commit\n",
        "logger.info(f\"Running on {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sSKiXfFjzzk",
        "outputId": "85826e94-ddbc-45af-9193-d6fea0af39a8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving to save/dev_perturb_adamson-Jul24-17-33\n",
            "scGPT - INFO - Running on 2024-07-24 17:33:06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pert_data = PertData(\"./data\")\n",
        "pert_data.load(data_name=data_name)\n",
        "pert_data.prepare_split(split=split, seed=1)\n",
        "pert_data.get_dataloader(batch_size=batch_size, test_batch_size=eval_batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwaGr3dtj3SE",
        "outputId": "45e8a699-e606-4173-d80a-93f6bffd2b04"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found local copy...\n",
            "Local copy of pyg dataset is detected. Loading...\n",
            "Done!\n",
            "Local copy of split is detected. Loading...\n",
            "Simulation split test composition:\n",
            "combo_seen0:0\n",
            "combo_seen1:0\n",
            "combo_seen2:0\n",
            "unseen_single:22\n",
            "Done!\n",
            "Creating dataloaders....\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if load_model is not None:\n",
        "    model_dir = Path(load_model)\n",
        "    model_config_file = model_dir / \"args.json\"\n",
        "    model_file = model_dir / \"best_model.pt\"\n",
        "    vocab_file = model_dir / \"vocab.json\"\n",
        "\n",
        "    vocab = GeneVocab.from_file(vocab_file)\n",
        "    for s in special_tokens:\n",
        "        if s not in vocab:\n",
        "            vocab.append_token(s)\n",
        "\n",
        "    pert_data.adata.var[\"id_in_vocab\"] = [\n",
        "        1 if gene in vocab else -1 for gene in pert_data.adata.var[\"gene_name\"]\n",
        "    ]\n",
        "    gene_ids_in_vocab = np.array(pert_data.adata.var[\"id_in_vocab\"])\n",
        "    logger.info(\n",
        "        f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
        "        f\"in vocabulary of size {len(vocab)}.\"\n",
        "    )\n",
        "    genes = pert_data.adata.var[\"gene_name\"].tolist()\n",
        "\n",
        "    # model\n",
        "    with open(model_config_file, \"r\") as f:\n",
        "        model_configs = json.load(f)\n",
        "    logger.info(\n",
        "        f\"Resume model from {model_file}, the model args will override the \"\n",
        "        f\"config {model_config_file}.\"\n",
        "    )\n",
        "    embsize = model_configs[\"embsize\"]\n",
        "    nhead = model_configs[\"nheads\"]\n",
        "    d_hid = model_configs[\"d_hid\"]\n",
        "    nlayers = model_configs[\"nlayers\"]\n",
        "    n_layers_cls = model_configs[\"n_layers_cls\"]\n",
        "else:\n",
        "    genes = pert_data.adata.var[\"gene_name\"].tolist()\n",
        "    vocab = Vocab(\n",
        "        VocabPybind(genes + special_tokens, None)\n",
        "    )  # bidirectional lookup [gene <-> int]\n",
        "vocab.set_default_index(vocab[\"<pad>\"])\n",
        "gene_ids = np.array(\n",
        "    [vocab[gene] if gene in vocab else vocab[\"<pad>\"] for gene in genes], dtype=int\n",
        ")\n",
        "n_genes = len(genes)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvZAe2Uej8LI",
        "outputId": "e4f41625-6faf-49a5-956a-862b56ea0f7f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scGPT - INFO - match 4399/5060 genes in vocabulary of size 60697.\n",
            "scGPT - INFO - Resume model from /content/drive/MyDrive/save/scGPT_human/best_model.pt, the model args will override the config /content/drive/MyDrive/save/scGPT_human/args.json.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and train scGpt\n",
        "\n"
      ],
      "metadata": {
        "id": "gkjLm8RCok6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "ntokens = len(vocab)  # size of vocabulary\n",
        "model = TransformerGenerator(\n",
        "    ntokens,\n",
        "    embsize,\n",
        "    nhead,\n",
        "    d_hid,\n",
        "    nlayers,\n",
        "    nlayers_cls=n_layers_cls,\n",
        "    n_cls=1,\n",
        "    vocab=vocab,\n",
        "    dropout=dropout,\n",
        "    pad_token=pad_token,\n",
        "    pad_value=pad_value,\n",
        "    pert_pad_id=pert_pad_id,\n",
        "    use_fast_transformer=use_fast_transformer,\n",
        ")\n",
        "\n",
        "def load_pretrained_model(model, model_file, load_param_prefixs=None):\n",
        "    model_dict = model.state_dict()\n",
        "    pretrained_dict = torch.load(model_file)\n",
        "\n",
        "    if load_param_prefixs is not None:\n",
        "        pretrained_dict = {\n",
        "            k: v\n",
        "            for k, v in pretrained_dict.items()\n",
        "            if any([k.startswith(prefix) for prefix in load_param_prefixs])\n",
        "        }\n",
        "    else:\n",
        "        pretrained_dict = {\n",
        "            k: v\n",
        "            for k, v in pretrained_dict.items()\n",
        "            if k in model_dict and v.shape == model_dict[k].shape\n",
        "        }\n",
        "\n",
        "    for k, v in pretrained_dict.items():\n",
        "        logger.info(f\"Loading params {k} with shape {v.shape}\")\n",
        "\n",
        "    model_dict.update(pretrained_dict)\n",
        "    model.load_state_dict(model_dict)\n",
        "\n",
        "if load_model is not None:\n",
        "    try:\n",
        "        load_pretrained_model(model, model_file, load_param_prefixs)\n",
        "        logger.info(f\"Loading model params from {model_file}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading model params: {e}\")\n",
        "\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQBQ3YfuknPD",
        "outputId": "21acca5a-ce39-404a-b150-a06d5eda24d6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using simple batchnorm instead of domain specific batchnorm\n",
            "scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])\n",
            "scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])\n",
            "scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])\n",
            "scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])\n",
            "scGPT - ERROR - Error loading model params: Error(s) in loading state_dict for TransformerGenerator:\n",
            "\tUnexpected key(s) in state_dict: \"transformer_encoder.layers.0.self_attn.Wqkv.weight\", \"transformer_encoder.layers.0.self_attn.Wqkv.bias\", \"transformer_encoder.layers.1.self_attn.Wqkv.weight\", \"transformer_encoder.layers.1.self_attn.Wqkv.bias\", \"transformer_encoder.layers.2.self_attn.Wqkv.weight\", \"transformer_encoder.layers.2.self_attn.Wqkv.bias\", \"transformer_encoder.layers.3.self_attn.Wqkv.weight\", \"transformer_encoder.layers.3.self_attn.Wqkv.bias\", \"transformer_encoder.layers.4.self_attn.Wqkv.weight\", \"transformer_encoder.layers.4.self_attn.Wqkv.bias\", \"transformer_encoder.layers.5.self_attn.Wqkv.weight\", \"transformer_encoder.layers.5.self_attn.Wqkv.bias\", \"transformer_encoder.layers.6.self_attn.Wqkv.weight\", \"transformer_encoder.layers.6.self_attn.Wqkv.bias\", \"transformer_encoder.layers.7.self_attn.Wqkv.weight\", \"transformer_encoder.layers.7.self_attn.Wqkv.bias\", \"transformer_encoder.layers.8.self_attn.Wqkv.weight\", \"transformer_encoder.layers.8.self_attn.Wqkv.bias\", \"transformer_encoder.layers.9.self_attn.Wqkv.weight\", \"transformer_encoder.layers.9.self_attn.Wqkv.bias\", \"transformer_encoder.layers.10.self_attn.Wqkv.weight\", \"transformer_encoder.layers.10.self_attn.Wqkv.bias\", \"transformer_encoder.layers.11.self_attn.Wqkv.weight\", \"transformer_encoder.layers.11.self_attn.Wqkv.bias\". \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerGenerator(\n",
              "  (encoder): GeneEncoder(\n",
              "    (embedding): Embedding(60697, 512, padding_idx=60694)\n",
              "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (value_encoder): ContinuousValueEncoder(\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (linear1): Linear(in_features=1, out_features=512, bias=True)\n",
              "    (activation): ReLU()\n",
              "    (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (pert_encoder): Embedding(3, 512, padding_idx=2)\n",
              "  (bn): BatchNorm1d(512, eps=6.1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (transformer_encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-11): 12 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout2): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): ExprDecoder(\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (1): LeakyReLU(negative_slope=0.01)\n",
              "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (3): LeakyReLU(negative_slope=0.01)\n",
              "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (cls_decoder): ClsDecoder(\n",
              "    (_decoder): ModuleList(\n",
              "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (4): ReLU()\n",
              "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (out_layer): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              "  (sim): Similarity(\n",
              "    (cos): CosineSimilarity()\n",
              "  )\n",
              "  (creterion_cce): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = masked_mse_loss\n",
        "criterion_cls = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, schedule_interval, gamma=0.9)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
        "\n",
        "\n",
        "def train(model: nn.Module, train_loader: torch.utils.data.DataLoader) -> None:\n",
        "    \"\"\"\n",
        "    Train the model for one epoch.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss, total_mse = 0.0, 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    num_batches = len(train_loader)\n",
        "    for batch, batch_data in enumerate(train_loader):\n",
        "        batch_size = len(batch_data.y)\n",
        "        batch_data.to(device)\n",
        "        x: torch.Tensor = batch_data.x  # (batch_size * n_genes, 2)\n",
        "        ori_gene_values = x[:, 0].view(batch_size, n_genes)\n",
        "        pert_flags = x[:, 1].long().view(batch_size, n_genes)\n",
        "        target_gene_values = batch_data.y  # (batch_size, n_genes)\n",
        "\n",
        "        if include_zero_gene in [\"all\", \"batch-wise\"]:\n",
        "            if include_zero_gene == \"all\":\n",
        "                input_gene_ids = torch.arange(n_genes, device=device, dtype=torch.long)\n",
        "            else:\n",
        "                input_gene_ids = (\n",
        "                    ori_gene_values.nonzero()[:, 1].flatten().unique().sort()[0]\n",
        "                )\n",
        "            # sample input_gene_id\n",
        "            if len(input_gene_ids) > max_seq_len:\n",
        "                input_gene_ids = torch.randperm(len(input_gene_ids), device=device)[\n",
        "                    :max_seq_len\n",
        "                ]\n",
        "            input_values = ori_gene_values[:, input_gene_ids]\n",
        "            input_pert_flags = pert_flags[:, input_gene_ids]\n",
        "            target_values = target_gene_values[:, input_gene_ids]\n",
        "\n",
        "            mapped_input_gene_ids = map_raw_id_to_vocab_id(input_gene_ids, gene_ids)\n",
        "            mapped_input_gene_ids = mapped_input_gene_ids.repeat(batch_size, 1)\n",
        "\n",
        "            # src_key_padding_mask = mapped_input_gene_ids.eq(vocab[pad_token])\n",
        "            src_key_padding_mask = torch.zeros_like(\n",
        "                input_values, dtype=torch.bool, device=device\n",
        "            )\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=amp):\n",
        "            output_dict = model(\n",
        "                mapped_input_gene_ids,\n",
        "                input_values,\n",
        "                input_pert_flags,\n",
        "                src_key_padding_mask=src_key_padding_mask,\n",
        "                CLS=CLS,\n",
        "                CCE=CCE,\n",
        "                MVC=MVC,\n",
        "                ECS=ECS,\n",
        "            )\n",
        "            output_values = output_dict[\"mlm_output\"]\n",
        "\n",
        "            masked_positions = torch.ones_like(\n",
        "                input_values, dtype=torch.bool\n",
        "            )  # Use all\n",
        "            loss = loss_mse = criterion(output_values, target_values, masked_positions)\n",
        "\n",
        "        model.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        with warnings.catch_warnings(record=True) as w:\n",
        "            warnings.filterwarnings(\"always\")\n",
        "            torch.nn.utils.clip_grad_norm_(\n",
        "                model.parameters(),\n",
        "                1.0,\n",
        "                error_if_nonfinite=False if scaler.is_enabled() else True,\n",
        "            )\n",
        "            if len(w) > 0:\n",
        "                logger.warning(\n",
        "                    f\"Found infinite gradient. This may be caused by the gradient \"\n",
        "                    f\"scaler. The current scale is {scaler.get_scale()}. This warning \"\n",
        "                    \"can be ignored if no longer occurs after autoscaling of the scaler.\"\n",
        "                )\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # torch.cuda.empty_cache()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_mse += loss_mse.item()\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            cur_mse = total_mse / log_interval\n",
        "            # ppl = math.exp(cur_loss)\n",
        "            logger.info(\n",
        "                f\"| epoch {epoch:3d} | {batch:3d}/{num_batches:3d} batches | \"\n",
        "                f\"lr {lr:05.4f} | ms/batch {ms_per_batch:5.2f} | \"\n",
        "                f\"loss {cur_loss:5.2f} | mse {cur_mse:5.2f} |\"\n",
        "            )\n",
        "            total_loss = 0\n",
        "            total_mse = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module, val_loader: torch.utils.data.DataLoader) -> float:\n",
        "    \"\"\"\n",
        "    Evaluate the model on the evaluation data.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_error = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch, batch_data in enumerate(val_loader):\n",
        "            batch_size = len(batch_data.y)\n",
        "            batch_data.to(device)\n",
        "            x: torch.Tensor = batch_data.x  # (batch_size * n_genes, 2)\n",
        "            ori_gene_values = x[:, 0].view(batch_size, n_genes)\n",
        "            pert_flags = x[:, 1].long().view(batch_size, n_genes)\n",
        "            target_gene_values = batch_data.y  # (batch_size, n_genes)\n",
        "\n",
        "            if include_zero_gene in [\"all\", \"batch-wise\"]:\n",
        "                if include_zero_gene == \"all\":\n",
        "                    input_gene_ids = torch.arange(n_genes, device=device)\n",
        "                else:  # when batch-wise\n",
        "                    input_gene_ids = (\n",
        "                        ori_gene_values.nonzero()[:, 1].flatten().unique().sort()[0]\n",
        "                    )\n",
        "\n",
        "                # sample input_gene_id\n",
        "                if len(input_gene_ids) > max_seq_len:\n",
        "                    input_gene_ids = torch.randperm(len(input_gene_ids), device=device)[\n",
        "                        :max_seq_len\n",
        "                    ]\n",
        "                input_values = ori_gene_values[:, input_gene_ids]\n",
        "                input_pert_flags = pert_flags[:, input_gene_ids]\n",
        "                target_values = target_gene_values[:, input_gene_ids]\n",
        "\n",
        "                mapped_input_gene_ids = map_raw_id_to_vocab_id(input_gene_ids, gene_ids)\n",
        "                mapped_input_gene_ids = mapped_input_gene_ids.repeat(batch_size, 1)\n",
        "\n",
        "                # src_key_padding_mask = mapped_input_gene_ids.eq(vocab[pad_token])\n",
        "                src_key_padding_mask = torch.zeros_like(\n",
        "                    input_values, dtype=torch.bool, device=input_values.device\n",
        "                )\n",
        "            with torch.cuda.amp.autocast(enabled=amp):\n",
        "                output_dict = model(\n",
        "                    mapped_input_gene_ids,\n",
        "                    input_values,\n",
        "                    input_pert_flags,\n",
        "                    src_key_padding_mask=src_key_padding_mask,\n",
        "                    CLS=CLS,\n",
        "                    CCE=CCE,\n",
        "                    MVC=MVC,\n",
        "                    ECS=ECS,\n",
        "                    do_sample=True,\n",
        "                )\n",
        "                output_values = output_dict[\"mlm_output\"]\n",
        "\n",
        "                masked_positions = torch.ones_like(\n",
        "                    input_values, dtype=torch.bool, device=input_values.device\n",
        "                )\n",
        "                loss = criterion(output_values, target_values, masked_positions)\n",
        "            total_loss += loss.item()\n",
        "            total_error += masked_relative_error(\n",
        "                output_values, target_values, masked_positions\n",
        "            ).item()\n",
        "    return total_loss / len(val_loader), total_error / len(val_loader)\n"
      ],
      "metadata": {
        "id": "i7ZpjHH1o9ig"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric"
      ],
      "metadata": {
        "id": "u7jeIb5l1drF"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float(\"inf\")\n",
        "best_model = None\n",
        "patience = 0\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train_loader = pert_data.dataloader[\"train_loader\"]\n",
        "    new_batch_size = train_loader.batch_size // 16  # Reduce batch size by half\n",
        "    train_loader = torch_geometric.loader.DataLoader(train_loader.dataset, batch_size=new_batch_size, shuffle=True)  # Create a new DataLoader with reduced batch size\n",
        "\n",
        "\n",
        "\n",
        "    valid_loader = pert_data.dataloader[\"val_loader\"]\n",
        "    new_batch_size = valid_loader.batch_size // 16  # Reduce batch size by half\n",
        "    valid_loader = torch_geometric.loader.DataLoader(valid_loader.dataset, batch_size=new_batch_size, shuffle=False)  # Create a new DataLoader with reduced batch size\n",
        "\n",
        "\n",
        "\n",
        "    train(\n",
        "        model,\n",
        "        train_loader,\n",
        "    )\n",
        "    val_loss, val_mre = evaluate(\n",
        "        model,\n",
        "        valid_loader,\n",
        "    )\n",
        "    elapsed = time.time() - epoch_start_time\n",
        "    logger.info(\"-\" * 89)\n",
        "    logger.info(\n",
        "        f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
        "        f\"valid loss/mse {val_loss:5.4f} |\"\n",
        "    )\n",
        "    logger.info(\"-\" * 89)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = copy.deepcopy(model)\n",
        "        logger.info(f\"Best model with score {best_val_loss:5.4f}\")\n",
        "        patience = 0\n",
        "    else:\n",
        "        patience += 1\n",
        "        if patience >= early_stop:\n",
        "            logger.info(f\"Early stop at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "    torch.save(\n",
        "        model.state_dict(),\n",
        "        save_dir / f\"model_{epoch}.pt\",\n",
        "    )\n",
        "\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "6_0zEWvXosyf",
        "outputId": "d88f7f45-18f6-4060-af69-08e485b566e0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 39.56 GiB of which 18.81 MiB is free. Process 67064 has 39.54 GiB memory in use. Of the allocated memory 38.96 GiB is allocated by PyTorch, and 76.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-a99bf979e87d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     train(\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-bf9fee3063a9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             output_dict = model(\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mmapped_input_gene_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0minput_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scgpt/model/generation_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, values, input_pert_flags, src_key_padding_mask, CLS, CCE, MVC, ECS, do_sample)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Auto set do_sample to True when model is in eval mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         transformer_output = self._encode(\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_pert_flags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scgpt/model/generation_model.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(self, src, values, input_pert_flags, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mtotal_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         output = self.transformer_encoder(\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mtotal_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask_for_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_nested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m     def _sa_block(self, x: Tensor,\n\u001b[1;32m    714\u001b[0m                   attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: bool = False) -> Tensor:\n\u001b[0;32m--> 715\u001b[0;31m         x = self.self_attn(x, x, x,\n\u001b[0m\u001b[1;32m    716\u001b[0m                            \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                            \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1242\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5438\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5440\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5441\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 39.56 GiB of which 18.81 MiB is free. Process 67064 has 39.54 GiB memory in use. Of the allocated memory 38.96 GiB is allocated by PyTorch, and 76.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "92QM65O4za1p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}